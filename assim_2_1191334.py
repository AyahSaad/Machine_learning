# -*- coding: utf-8 -*-
"""Assim#2_1191334.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pISXa7bEhRPUuScfSCiw2EB3VsQ_I933

**PS:**





**Make sure to have a drive contain 3 files**
"""

import os
from google.colab import drive
drive.mount('/content/drive/')
cwd="/content/drive/MyDrive/Machine Learning Assim#2"
os.chdir(cwd)

pwd

"""Import **libraries** nedded"""

import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Ridge
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import PolynomialFeatures, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""**Model Selection** **and Hyper-parameters Tunning**





---


---

**First Step:**Reading dataset From the data_reg.csv file, split it into a training set (the first 120 examples), a validation set (the next 40 examples), and a testing set (the last 40 examples).



----
"""

# Read the dataset
file_path = 'data_reg.csv'
data = pd.read_csv(file_path)

# Split the data into training set
training_set = data[:120]
# Split the data into validation set
validation_set = data[120:160]
# Split the data into testing set
testing_set = data[160:]

# Optionally, you can reset the index of each set
training_set.reset_index(drop=True, inplace=True)
validation_set.reset_index(drop=True, inplace=True)
testing_set.reset_index(drop=True, inplace=True)

# Display the first few rows of each set (optional)
print("Training Set:")
print(training_set.head())
print("\nValidation Set:")
print(validation_set.head())
print("\nTesting Set:")
print(testing_set.head())

# Display the number of rows in each set
print("................................................................")
print("Number of examples in Training Set:", training_set.shape[0])
print("Number of examples in Validation Set:", validation_set.shape[0])
print("Number of examples in Testing Set:", testing_set.shape[0])

"""**A 3D scatter plot is created using three sets, each encoding with a different
color, to display the x1 and x2 features and the target label y.**
"""

# Plotting using Matplotlib
fig = plt.figure(figsize=(10, 10))
ax = fig.add_subplot(111, projection='3d')

# Define sets for iteration
sets = [('Training Set', training_set, 'green', 'o'),
        ('Validation Set', validation_set, 'blue', 'x'),
        ('Testing Set', testing_set, 'red', 's')]

# Loop through sets to create scatter plots
for label, dataset, color, marker in sets:
    ax.scatter(dataset['x1'], dataset['x2'], dataset['y'], label=label, c=color, marker=marker)

# Set axis labels
ax.set_xlabel('x1')
ax.set_ylabel('x2')
ax.set_zlabel('y')

# Set plot title
ax.set_title('3D Scatter Plot of Training, Validation, and Testing Sets')

# Add a legend
ax.legend()

# Show the plot
plt.show()

"""**Second Step:**Using polynomial regression on a training set with 1–10 degrees and comparing which degree is the best based on plotting the validation error vs. polynomial degree curve.


----
"""

# we save the x1 and x2 columns to X, the y column to y.
X1= training_set[['x1', 'x2']]
X2= validation_set[['x1', 'x2']]

# Define degrees for polynomial regression
degrees = np.arange(1,11)
# Define empty list (validation_errors) to store the validation errors for each degree
validation_errors = []

# Plotting using Matplotlib
fig = plt.figure(figsize=(15, 10))

# Iterate over polynomial degrees
for deg in degrees:
    # Transform features to polynomial features
    # Defining the training and the test data
    Polynomial = PolynomialFeatures(degree=deg)
    X_train_poly = Polynomial.fit_transform(X1)
    X_validation_poly = Polynomial.transform(X2)

    # Fit polynomial regression model
    poly_reg_model = LinearRegression()
    poly_reg_model.fit(X_train_poly, training_set['y'])

    # Here’s we can test how our model performs on unseen data
    # Predict on validation set
    poly_reg_y_predicted = poly_reg_model.predict(X_validation_poly)

    # Calculate validation error (MSE)
    poly_reg_rmse = mean_squared_error(validation_set['y'], poly_reg_y_predicted)
    validation_errors.append(poly_reg_rmse)

    # Print the MSE for each degree
    print(f'Degree #{deg}: MSE = {poly_reg_rmse}')

    # Plot the surface of the learned function alongside training examples
    ax = fig.add_subplot(2, 5, deg, projection='3d')
    ax.scatter(training_set['x1'], training_set['x2'], training_set['y'], c='green', marker='o', label='Training examples')
    ax.set_title(f'Degree #{deg}')

    # Create a meshgrid for plotting the surface
    x1_range = np.linspace(training_set['x1'].min(), training_set['x1'].max(), 100)
    x2_range = np.linspace(training_set['x2'].min(), training_set['x2'].max(), 100)
    x1_mesh, x2_mesh = np.meshgrid(x1_range, x2_range)
    X_mesh = np.column_stack((x1_mesh.ravel(), x2_mesh.ravel()))
    X_poly_mesh = Polynomial.transform(X_mesh)

    # Predict on the meshgrid
    y_mesh_pred = poly_reg_model.predict(X_poly_mesh)
    y_mesh_pred = y_mesh_pred.reshape(x1_mesh.shape)

    # Plot the surface
    ax.plot_surface(x1_mesh, x2_mesh, y_mesh_pred, color='red', alpha=0.5, label='Learned Function')
    ax.set_xlabel('x1')
    ax.set_ylabel('x2')
    ax.set_zlabel('y')

# Plot validation error vs polynomial degree curve
plt.figure(figsize=(10, 8))
plt.plot(degrees, validation_errors, marker='o', linestyle='-', color='Green')
plt.title('Validation Error vs Polynomial Degree curve')
plt.xlabel('Polynomial Degree')
plt.ylabel('Validation Error (MSE)')
plt.grid(True)
plt.show()

"""**The study used polynomial regression with degrees ranging from 1 to 10, and the validation error was computed for each degree.** **The model with degree 2 showed optimal performance, with a steady decrease up to degree 2 and an increase thereafter. We noticed that the mean squared error of degree 2 was 0.1799, indicating its best-performing degree for the dataset.**

Degree #2: MSE = 0.17990349576391843

**Third Step:**Using ridge regression to fit a degree 8 polynomial on the training set, selecting the optimal regularization parameter from a range of 0.001, 0.005, 0.01, 0.1, and 10, and plotting the MSE on the validation vs. the regularization parameter.


----
"""

# Define the polynomial degree
poly_degree = 8
# Define regularization parameter options
reg_par = [0.001, 0.005, 0.01, 0.1, 10]

# Initialize variables to store the best alpha and corresponding MSE
best_param = None
best_mse = float('inf')

# Initialize (values) list to store MSE values for each alpha
mse_list = []

# Iterate over parameter values
for parameter in reg_par:
    # Transform features to polynomial features
    Polynomial = PolynomialFeatures(degree=poly_degree)
    X_train_poly = Polynomial.fit_transform(training_set[['x1', 'x2']])
    X_validation_poly = Polynomial.transform(validation_set[['x1', 'x2']])

    # Fit Ridge regression model
    ridge_reg_model = Ridge(alpha=parameter)
    ridge_reg_model.fit(X_train_poly, training_set['y'])

    # Predict on validation set
    y_validation_prediction = ridge_reg_model.predict(X_validation_poly)

    # Calculate mean squared error (MSE) for the current alpha
    mse = mean_squared_error(validation_set['y'], y_validation_prediction)
    mse_list.append(mse)

    # Print the MSE for each Regularization Parameter
    print(f'Regularization Parameter ({parameter}) MSE = {mse}')

    # Update the best alpha if the current alpha yields a lower MSE
    if mse < best_mse:
        best_mse = mse
        best_param = parameter
print(".........................................................")
# Print the best parameter and corresponding MSE
print(f"Best Regularization Parameter: {best_param}")
print(f"Corresponding MSE on Validation Set: {best_mse}")

# Plot MSE on validation vs regularization parameter
plt.figure(figsize=(10,8))
plt.plot(reg_par,mse_list, marker='o', linestyle='-', color='Purple')
plt.xscale('log')
plt.title('Mean Squared Error on Validation vs Regularization Parameter')
plt.xlabel('Regularization Parameter')
plt.ylabel('Mean Squared Error on Validation Set')
plt.grid(True)
plt.show()

"""**A study on Ridge regression on a degree 8 polynomial training set found that the best regularization parameter was 0.01, resulting in a mean squared error of 0.2099 on the validation set.**

Best Regularization Parameter: 0.01

Corresponding MSE on Validation Set: 0.20996554038850396

**Logistic** Regression


---



---

**First Step:** Here we using the logistic regression implementation of scikit-learn library, to learn a logistic regression model with a linear decision boundary, Drawing the decision boundary of the learned model on a scatterplot of the training set and Computing the training and testing accuracy of the learned model.

----
"""

import pandas as pd
# Read the train dataset
train_file_path = 'train_cls.csv'
train_data = pd.read_csv(train_file_path)
# Read the test dataset
test_file_path = 'test_cls.csv'
test_data = pd.read_csv(test_file_path)

# Encode class labels to numerical values
label_encoder = LabelEncoder()
train_data['class'] = label_encoder.fit_transform(train_data['class'])
test_data['class'] = label_encoder.transform(test_data['class'])

# Split the data into features (X) and target variable (y) for training set
X_train = train_data[['x1', 'x2']]
y_train = train_data['class']

# Split the data into features (X) and target variable (y) for testing set
X_test = test_data[['x1', 'x2']]
y_test = test_data['class']

# Create a logistic regression model
logistic_regression_model = LogisticRegression()

# Train the model on the training set
logistic_regression_model.fit(X_train, y_train)

# Make predictions on the training set
y_train_prediction = logistic_regression_model.predict(X_train)

# Make predictions on the testing set
y_test_prediction = logistic_regression_model.predict(X_test)

# Compute accuracy,precision, recall, and F1-score for training set
train_accuracy = accuracy_score(y_train, y_train_prediction)
precision_train = precision_score(y_train, y_train_prediction)
recall_train = recall_score(y_train, y_train_prediction)
f1_train = f1_score(y_train, y_train_prediction)

# Compute accuracy,precision, recall, and F1-score for testing set
test_accuracy = accuracy_score(y_test, y_test_prediction)
precision_test = precision_score(y_test, y_test_prediction)
recall_test = recall_score(y_test, y_test_prediction)
f1_test = f1_score(y_test, y_test_prediction)

h = 0.01  # step size in the mesh

# Plot the decision boundary for training set
x_min, x_max = X_train['x1'].min() - 1, X_train['x1'].max() + 1
y_min, y_max = X_train['x2'].min() - 1, X_train['x2'].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
Z = logistic_regression_model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)

plt.figure(figsize=(10, 8))
# add decision boundary countour map
plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)
scatter = plt.scatter(X_train['x1'], X_train['x2'], c=y_train, edgecolors='k', cmap=plt.cm.Paired, label='Training Set')
plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Logistic Regression with Linear Decision Boundary')
plt.legend(handles=scatter.legend_elements()[0], labels=['C1', 'C2'], loc='upper right')
plt.show()


# Display Accuracy,precision, recall, and F1-score
print(f'Testing Accuracy: {train_accuracy:.2f}')
print(f'Training Accuracy: {test_accuracy:.2f}')

print(".................................................................................................")
print("")
print("These metrics provide a more detailed understanding of the logistic regression model performance ")
print("")
print("Training Precision:", precision_train)
print("Training Recall:", recall_train)
print("Training F1-Score:", f1_train)
print("")
print("Testing Precision:", precision_test)
print("Testing Recall:", recall_test)
print("Testing F1-Score:", f1_test)

"""***Plot the decision boundary for testing set***




---


"""

# Plot the decision boundary for testing set
x_min_t, x_max_t = X_test['x1'].min() - 1, X_test['x1'].max() + 1
y_min_t, y_max_t = X_test['x2'].min() - 1, X_test['x2'].max() + 1
xx_t, yy_t = np.meshgrid(np.arange(x_min_t, x_max_t, h), np.arange(y_min_t, y_max_t, h))
Z_t = logistic_regression_model.predict(np.c_[xx_t.ravel(), yy_t.ravel()]).reshape(xx_t.shape)

plt.figure(figsize=(10, 8))
# add decision boundary countour map
plt.contourf(xx_t, yy_t, Z_t, alpha=0.3, cmap=plt.cm.Paired)
scatter = plt.scatter(X_test['x1'], X_test['x2'], c=y_test, edgecolors='k', cmap=plt.cm.Paired, label='Testing Set')
plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Logistic Regression with Linear Decision Boundary')
plt.legend(handles=scatter.legend_elements()[0], labels=['C1', 'C2'], loc='upper right')
plt.show()

"""**Second Step:** Here we using the logistic regression implementation of scikit-learn library, to learn a logistic regression model with a quadratic decision boundary, Drawing the decision boundary of the learned model on a scatterplot of the training set and Computing the training and testing accuracy of the learned model.


----
"""

import pandas as pd
# Read the train dataset
train_file_path = 'train_cls.csv'
train_data = pd.read_csv(train_file_path)
# Read the test dataset
test_file_path = 'test_cls.csv'
test_data = pd.read_csv(test_file_path)

# Encode class labels to numerical values
label_encoder = LabelEncoder()
train_data['class'] = label_encoder.fit_transform(train_data['class'])
test_data['class'] = label_encoder.transform(test_data['class'])

# Split the data into features (X) and target variable (y) for training set
X_train = train_data[['x1', 'x2']]
y_train = train_data['class']

# Split the data into features (X) and target variable (y) for testing set
X_test = test_data[['x1', 'x2']]
y_test = test_data['class']

# Create polynomial features for both training and testing sets
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

# Create a logistic regression model
logistic_regression_model = LogisticRegression()

# Train the model on the polynomial features of the training set
logistic_regression_model.fit(X_train_poly, y_train)

# Make predictions on the polynomial features of the training set
y_train_prediction = logistic_regression_model.predict(X_train_poly)

# Make predictions on the polynomial features of the testing set
y_test_prediction = logistic_regression_model.predict(X_test_poly)

# Compute accuracy,precision, recall, and F1-score for training set
train_accuracy = accuracy_score(y_train, y_train_prediction)
precision_train = precision_score(y_train, y_train_prediction)
recall_train = recall_score(y_train, y_train_prediction)
f1_train = f1_score(y_train, y_train_prediction)

# Compute accuracy,precision, recall, and F1-score for testing set
test_accuracy = accuracy_score(y_test, y_test_prediction)
precision_test = precision_score(y_test, y_test_prediction)
recall_test = recall_score(y_test, y_test_prediction)
f1_test = f1_score(y_test, y_test_prediction)

h = 0.01  # step size in the mesh

# Scatter plot of the training set with quadratic decision boundary
x_min, x_max = X_train['x1'].min() - 1, X_train['x1'].max() + 1
y_min, y_max = X_train['x2'].min() - 1, X_train['x2'].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
Z = logistic_regression_model.predict(poly.transform(np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)

plt.figure(figsize=(10, 8))
# add decision boundary countour map
plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)
scatter = plt.scatter(X_train['x1'], X_train['x2'], c=y_train, edgecolors='k', cmap=plt.cm.Paired, label='Training Set')
plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Logistic Regression with Quadratic Decision Boundary')
plt.legend(handles=scatter.legend_elements()[0], labels=['C1', 'C2'], loc='upper right')
plt.show()

# Display Accuracy,precision, recall, and F1-score
print(f'Testing Accuracy: {train_accuracy:.2f}')
print(f'Training Accuracy: {test_accuracy:.2f}')

print(".................................................................................................")
print("")
print("These metrics provide a more detailed understanding of the logistic regression model performance ")
print("")
print("Training Precision:", precision_train)
print("Training Recall:", recall_train)
print("Training F1-Score:", f1_train)
print("")
print("Testing Precision:", precision_test)
print("Testing Recall:", recall_test)
print("Testing F1-Score:", f1_test)

"""***Plot the decision boundary for testing set***




---


"""

# Scatter plot of the testing set with quadratic decision boundary
x_min_t, x_max_t = X_test['x1'].min() - 1, X_test['x1'].max() + 1
y_min_t, y_max_t = X_test['x2'].min() - 1, X_test['x2'].max() + 1
xx_t, yy_t = np.meshgrid(np.arange(x_min_t, x_max_t, h), np.arange(y_min_t, y_max_t, h))
Z_t = logistic_regression_model.predict(poly.transform(np.c_[xx_t.ravel(), yy_t.ravel()])).reshape(xx_t.shape)

plt.figure(figsize=(10, 8))
# add decision boundary countour map
plt.contourf(xx_t, yy_t, Z_t, alpha=0.3, cmap=plt.cm.Paired)
scatter = plt.scatter(X_test['x1'], X_test['x2'], c=y_test, edgecolors='k', cmap=plt.cm.Paired, label='Testing Set')
plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Logistic Regression with Quadratic Decision Boundary')
plt.legend(handles=scatter.legend_elements()[0], labels=['C1', 'C2'], loc='upper right')
plt.show()

"""**Third Step:** Comment on the learned models in 1 and 2 in terms of overfitting/underfitting.


---

The metrics and visualization help in understanding how well the model is performing and if there are any signs of overfitting or underfitting.
"""